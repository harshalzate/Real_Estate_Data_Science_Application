{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshalzate/Real_Estate_Data_Science_Application/blob/main/NoteBooks/Web_Scraping/Real_Estate_apartments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "e7sinWGBBWQZ",
        "outputId": "59fd79ce-e522-42c8-9bde-7cf3a75f117b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"1080\"\n",
              "            height=\"500\"\n",
              "            src=\"https://www.99acres.com/property-in-gurgaon-ffid-page\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f6e58715240>"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "from IPython.display import IFrame\n",
        "url = 'https://www.99acres.com/property-in-gurgaon-ffid-page'\n",
        "IFrame(url, height=500, width=1080)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4cCnAnnq_Fi5"
      },
      "outputs": [],
      "source": [
        "# Importing Libraries\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "\n",
        "# Headers set like below:\n",
        "# User Agent\n",
        "headers = {\n",
        "    'authority': 'www.99acres.com',\n",
        "    'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',\n",
        "    'accept-language': 'en-US,en;q=0.9',\n",
        "    'cache-control': 'no-cache',\n",
        "    'dnt': '1',\n",
        "    'pragma': 'no-cache',\n",
        "    'referer': 'https://www.99acres.com/property-in-gurgaon-ffid',\n",
        "    'sec-ch-ua': '\"Chromium\";v=\"107\", \"Not;A=Brand\";v=\"8\"',\n",
        "    'sec-ch-ua-mobile': '?0',\n",
        "    'sec-ch-ua-platform': '\"macOS\"',\n",
        "    'sec-fetch-dest': 'document',\n",
        "    'sec-fetch-mode': 'navigate',\n",
        "    'sec-fetch-site': 'same-origin',\n",
        "    'sec-fetch-user': '?1',\n",
        "    'upgrade-insecure-requests': '1',\n",
        "    'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/527.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36',\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LD6RnnME_PlJ"
      },
      "outputs": [],
      "source": [
        "# Extract function\n",
        "def extract_data(pageSoup):\n",
        "    global i\n",
        "    d = pd.DataFrame()\n",
        "   se for soup in pageSoup.select_one('div[data-label=\"SEARCH\"]').select('section[data-hydration-on-demand=\"true\"]'):\n",
        "\n",
        "        # Extract property name and property sub-name\n",
        "        try:\n",
        "            property_name = soup.find('a', class_='projectTuple__projectName').text.strip()\n",
        "            property_sub_name = soup.find('h2', class_='projectTuple__subHeadingWrap').text.strip()\n",
        "            # print(property_name+'\\n'+property_sub_name)\n",
        "            # Extract link\n",
        "            link = soup.select_one('a', class_='projectTuple__projectName')['href']\n",
        "\n",
        "            page = requests.get(link, headers=headers)\n",
        "            dpageSoup = BeautifulSoup(page.content, 'html.parser')\n",
        "            top_f=[]\n",
        "            top_facilities = dpageSoup.find('div',id='top-facilities').find_all('div', class_=\"UniquesFacilities__xidFacilitiesCard\")\n",
        "            for facilities in top_facilities :\n",
        "                top_f.append(facilities.text.strip())\n",
        "\n",
        "            # print(top_f)\n",
        "            # Extract Nearbay Locations with Distances\n",
        "            LocationAdvantages = {}\n",
        "            for l in dpageSoup.select_one('div[data-label=\"LOCATION_HIGHLIGHTS\"]').select('div.locAdvantagesCard__locAdCard'):\n",
        "                t = l.find('div').find_all('div')\n",
        "                loaction = t[0].text.strip()\n",
        "                distance = t[1].text.strip()\n",
        "                LocationAdvantages[loaction] = distance\n",
        "\n",
        "            # Extract nearby locations\n",
        "            nearby_elements = soup.find_all('div', class_=\"SliderTagsAndChips__container\")[0].find_all('li', class_ = 'SliderTagsAndChips__item')\n",
        "            nearby = [element.text.strip() for element in nearby_elements]\n",
        "\n",
        "\n",
        "            #price Range\n",
        "            price_range = soup.find('div', class_=\"pageComponent configurationCards__srpCardStyle\").text\n",
        "\n",
        "            # Extract price details\n",
        "            prices_details = {}\n",
        "            price_elements =  soup.find('div', class_ = 'carousel__CarouselBox').find_all('div', class_=\"configurationCards__cardContainer\")\n",
        "            for element in price_elements:\n",
        "                bedroom_type = element.select_one('span.configurationCards__configBandLabel').text.strip()\n",
        "                building_type = element.select_one('span.configurationCards__configBandHeading').text.strip()\n",
        "                area_type = element.select_one('span.configurationCards__cardAreaTypeStyle').text.strip()\n",
        "                area = element.select_one('span.configurationCards__cardAreaSubHeadingOne').text.strip()\n",
        "                price_range = element.select_one('span.configurationCards__cardPriceHeading').text.strip()\n",
        "\n",
        "                prices_details[bedroom_type] = {\n",
        "                    'building_type': building_type,\n",
        "                    'area_type' : area_type,\n",
        "                    'area': area,\n",
        "                    'price-range': price_range\n",
        "                }\n",
        "            # # Print the extracted data\n",
        "            # print(\"Property Name: \", property_name)\n",
        "            # print(\"Property Sub-name: \", property_sub_name)\n",
        "            # print(\"Nearby Locations: \", nearby)\n",
        "            # print(\"Location Advantages: \", LocationAdvantages)\n",
        "            # print(\"Link: \", link)\n",
        "            # print(\"Price Details: \", prices_details)\n",
        "            # print('Top Facilities: ', top_f)\n",
        "\n",
        "\n",
        "            # Create a dictionary with the given variables\n",
        "            data_dict = {\n",
        "                \"PropertyName\": property_name,\n",
        "                \"PropertySubName\": property_sub_name,\n",
        "                \"NearbyLocations\": nearby,\n",
        "                \"LocationAdvantages\": LocationAdvantages,\n",
        "                \"Link\": link,\n",
        "                \"PriceDetails\": prices_details,\n",
        "                \"TopFacilities\": top_f\n",
        "            }\n",
        "\n",
        "            temp_df = pd.DataFrame.from_records([data_dict])\n",
        "            # print(temp_df)\n",
        "            d = pd.concat([d, temp_df], ignore_index=True)\n",
        "\n",
        "\n",
        "        except:\n",
        "            # print('No Data')\n",
        "            pass\n",
        "        i += 1\n",
        "    return d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaQzr-7-_RXw",
        "outputId": "4450ea86-1283-47f1-c5de-4ff0b45f4ffa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n",
            "Request Might be decline- waiting for 50 sec to request again.\n"
          ]
        }
      ],
      "source": [
        "pageNumber=1\n",
        "i=1\n",
        "# Create an empty DataFrame\n",
        "df = pd.DataFrame()\n",
        "\n",
        "# Specify the file path for the CSV file\n",
        "file_path = \"appartment_data.csv\"\n",
        "# df.to_csv(file_path, mode='a', index=False)\n",
        "\n",
        "while pageNumber < 50:\n",
        "    URL = f'https://www.99acres.com/property-in-gurgaon-ffid-page-{pageNumber}'\n",
        "    page = requests.get(URL, headers=headers)\n",
        "    pageSoup = BeautifulSoup(page.content, 'html.parser')\n",
        "    try:\n",
        "        data = extract_data(pageSoup)\n",
        "\n",
        "        # Append the dictionary as a row in the DataFrame\n",
        "        if df.empty:\n",
        "            df = pd.concat([data, df], ignore_index=True)\n",
        "            data.to_csv(file_path, index=False)\n",
        "        else:\n",
        "            df = pd.concat([data, df], ignore_index=True)\n",
        "            data.to_csv(file_path, mode='a', index=False, header=False)\n",
        "\n",
        "        print(f\"Data Extracted from {pageNumber}  : {data.shape}. Total Data : {df.shape} \")\n",
        "        pageNumber += 1\n",
        "    except:\n",
        "        print(\"Request Might be decline- waiting for 50 sec to request again.\")\n",
        "        time.sleep(50)\n",
        "# print(soup.prettify())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2uuaokZB5sD"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Htc2NxiCmR7"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('/content/appartment_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02S1IqiuC18C"
      },
      "outputs": [],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aefGZKEFER9d"
      },
      "outputs": [],
      "source": [
        "data.drop_duplicates()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}